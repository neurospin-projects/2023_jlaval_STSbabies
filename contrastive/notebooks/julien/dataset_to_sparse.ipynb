{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18882/2823202103.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sparse\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sides = ['L']\n",
    "\"\"\"\n",
    "sulcus_list = ['F.Coll.-S.Rh.', 'S.F.median-S.F.pol.tr.-S.F.sup.', 'S.F.inf.-BROCA-S.Pe.C.inf.', \\\n",
    "               'S.Po.C.', 'fronto-parietal_medial_face.', 'F.I.P.', 'S.T.s.-S.GSM.', 'CINGULATE.', \\\n",
    "               'F.C.L.p.-S.GSM.', 'S.C.-S.Po.C.', 'S.F.inter.-S.F.sup.', 'F.C.M.post.-S.p.C.', \\\n",
    "               'S.s.P.-S.Pa.int.', 'S.Or.-S.Olf.', 'F.P.O.-S.Cu.-Sc.Cal.', 'S.F.marginal-S.F.inf.ant.', \\\n",
    "               'S.F.int.-F.C.M.ant.', 'S.T.i.-S.T.s.-S.T.pol.', 'S.F.int.-S.R.', 'Lobule_parietal_sup.', \\\n",
    "               'S.T.i.-S.O.T.lat.', 'S.Pe.C.', 'S.T.s.br.', 'Sc.Cal.-S.Li.', 'S.T.s.', 'F.C.L.p.-subsc.-F.C.L.a.-INSULA.', \\\n",
    "               'S.C.-sylv.', 'S.C.-S.Pe.C.', 'OCCIPITAL', 'S.Or.']\n",
    "\"\"\"\n",
    "sulcus_list = ['S.Or.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEWARE: we here assume that the skeletons, foldlabels and distbottoms are in the same order in their respective numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = '_rotated'\n",
    "#rotated = ''\n",
    "root_save_dir = f'/volatile/jl277509/data/UkBioBank/crops/{rotated}/2mm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:25<00:00, 25.51s/it]\n"
     ]
    }
   ],
   "source": [
    "# TODO: avoid copy paste between modalities\n",
    "for sulcus in tqdm(sulcus_list):\n",
    "    for side in sides:\n",
    "\n",
    "        data_dir = f'/neurospin/dico/data/deep_folding/current/datasets/UkBioBank/crops/2mm/{sulcus}/mask'\n",
    "        subjects = pd.read_csv(os.path.join(data_dir, f'{side}skeleton_subject.csv'))\n",
    "        subjects = subjects['Subject'].tolist()\n",
    "        skels = np.load(os.path.join(data_dir, f'{side}skeleton{rotated}.npy'))\n",
    "\n",
    "        # need to make sure that skels, foldlabels, and distbottoms have the same coordinates\n",
    "        foldlabels = np.load(os.path.join(data_dir, f'{side}label{rotated}.npy'))\n",
    "        foldlabels[skels==0]=0 # TODO: should be assert instead ?\n",
    "\n",
    "        distbottoms = np.load(os.path.join(data_dir, f'{side}distbottom{rotated}.npy'))\n",
    "        distbottoms[distbottoms==0]=-1\n",
    "        distbottoms[skels==0]=0\n",
    "\n",
    "        extremities = np.load(os.path.join(data_dir, f'{side}extremities{rotated}.npy'))\n",
    "        extremities[skels==0]=0\n",
    "        extremities[np.logical_and(skels!=0, extremities)]=-1\n",
    "\n",
    "        save_dir = f'{root_save_dir}/{sulcus}/mask/{side}skeleton_sparse'\n",
    "        if not os.path.isdir(os.path.join(save_dir, 'coords')):\n",
    "            os.makedirs(os.path.join(save_dir, 'coords'))\n",
    "        if not os.path.isdir(os.path.join(save_dir, 'skeleton')):\n",
    "            os.makedirs(os.path.join(save_dir, 'skeleton'))\n",
    "        if not os.path.isdir(os.path.join(save_dir, 'foldlabel')):\n",
    "            os.makedirs(os.path.join(save_dir, 'foldlabel'))\n",
    "        if not os.path.isdir(os.path.join(save_dir, 'distbottom')):\n",
    "            os.makedirs(os.path.join(save_dir, 'distbottom'))\n",
    "        if not os.path.isdir(os.path.join(save_dir, 'extremities')):\n",
    "            os.makedirs(os.path.join(save_dir, 'extremities'))\n",
    "\n",
    "        nb_subs = len(skels)\n",
    "        for k, subject in enumerate(subjects):\n",
    "            skel = skels[k,:,:,:,0]\n",
    "            s = sparse.COO.from_numpy(skel)\n",
    "            np.save(os.path.join(save_dir, f'coords/{side}{subject}_coords.npy'), s.coords)\n",
    "            np.save(os.path.join(save_dir, f'skeleton/{side}{subject}_skeleton_values.npy'), s.data)\n",
    "            fold = foldlabels[k,:,:,:,0]\n",
    "            s = sparse.COO.from_numpy(fold)\n",
    "            np.save(os.path.join(save_dir, f'foldlabel/{side}{subject}_foldlabel_values.npy'), s.data)\n",
    "            distb = distbottoms[k,:,:,:,0]\n",
    "            s = sparse.COO.from_numpy(distb)\n",
    "            np.save(os.path.join(save_dir, f'distbottom/{side}{subject}_distbottom_values.npy'), s.data)\n",
    "            extr = extremities[k,:,:,:,0]\n",
    "            s = sparse.COO.from_numpy(extr)\n",
    "            np.save(os.path.join(save_dir, f'extremities/{side}{subject}_extremities_values.npy'), s.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that distbottoms are consistent before and after conversion to sparse\n",
    "# DONE\n",
    "side = 'R'\n",
    "sulcus = 'CINGULATE.'\n",
    "root_save_dir = '/volatile/jl277509/data/UkBioBank/crops/2mm/'\n",
    "data_dir = f'/neurospin/dico/data/deep_folding/current/datasets/UkBioBank/crops/2mm/{sulcus}/mask'\n",
    "subjects = pd.read_csv(os.path.join(data_dir, f'{side}skeleton_subject.csv'))\n",
    "coords_dir = f'{root_save_dir}{sulcus}/mask/{side}skeleton_sparse/coords'\n",
    "distbottom_dir = f'{root_save_dir}{sulcus}/mask/{side}skeleton_sparse/distbottom'\n",
    "foldlabel_dir =  f'{root_save_dir}{sulcus}/mask/{side}skeleton_sparse/foldlabel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_to_numpy(data, coords, input_size, dtype):\n",
    "    \"\"\"\n",
    "    Convert coords and associated values to numpy array\n",
    "    \"\"\"\n",
    "    s = sparse.COO(coords, data, shape=input_size)\n",
    "    arr = s.todense()\n",
    "    arr = np.expand_dims(arr, axis=-1)\n",
    "    arr = arr.astype(dtype)\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check that the sparse distbottoms can be properly reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "distbottoms = np.load(os.path.join(data_dir, f'{side}distbottom.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for sub in tqdm(subjects.Subject):\n",
    "    distbottom_arr = np.load(os.path.join(distbottom_dir, f'R{sub}_distbottom_values.npy'))\n",
    "    coords_arr = np.load(os.path.join(coords_dir, f'R{sub}_coords.npy'))\n",
    "    sample_distbottoms = convert_sparse_to_numpy(distbottom_arr, coords_arr,\n",
    "                                                 [16,37,37], 'int32')\n",
    "    sample_distbottoms[sample_distbottoms==0]=32500\n",
    "    sample_distbottoms[sample_distbottoms==-1]=0\n",
    "    l.append(sample_distbottoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distbottoms_reconstructed = np.stack(l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore 32500 and 32501 values since they are the same : set them to same value\n",
    "distbottoms[distbottoms==32500]=32501\n",
    "distbottoms_reconstructed[distbottoms_reconstructed==32500]=32501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = distbottoms-distbottoms_reconstructed\n",
    "np.sum(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same for foldlabel ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldlabels = np.load(os.path.join(data_dir, f'{side}label.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21045/21045 [00:11<00:00, 1812.03it/s]\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for sub in tqdm(subjects.Subject):\n",
    "    foldlabel_arr = np.load(os.path.join(foldlabel_dir, f'R{sub}_foldlabel_values.npy'))\n",
    "    coords_arr = np.load(os.path.join(coords_dir, f'R{sub}_coords.npy'))\n",
    "    sample_foldlabels = convert_sparse_to_numpy(foldlabel_arr, coords_arr,\n",
    "                                                 [16,37,37], 'int32')\n",
    "    l.append(sample_foldlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldlabels_reconstructed = np.stack(l, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = foldlabels-foldlabels_reconstructed\n",
    "np.sum(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same for skeletons ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F.Coll.-S.Rh. size: 86428 vx\n",
      "S.F.inf.-BROCA-S.Pe.C.inf. size: 44720 vx\n",
      "S.Po.C. size: 57498 vx\n",
      "fronto-parietal_medial_face. size: 114144 vx\n",
      "S.T.s.-S.GSM. size: 63648 vx\n",
      "F.C.L.p.-S.GSM. size: 52245 vx\n",
      "S.C.-S.Po.C. size: 88494 vx\n",
      "S.F.inter.-S.F.sup. size: 82150 vx\n",
      "F.C.M.post.-S.p.C. size: 24769 vx\n",
      "S.s.P.-S.Pa.int. size: 33626 vx\n",
      "S.Or.-S.Olf. size: 28272 vx\n",
      "F.P.O.-S.Cu.-Sc.Cal. size: 60060 vx\n",
      "S.F.marginal-S.F.inf.ant. size: 44928 vx\n",
      "S.F.int.-F.C.M.ant. size: 52326 vx\n",
      "S.T.i.-S.T.s.-S.T.pol. size: 116424 vx\n",
      "S.F.int.-S.R. size: 57171 vx\n",
      "Lobule_parietal_sup. size: 88560 vx\n",
      "S.T.i.-S.O.T.lat. size: 110448 vx\n",
      "S.Pe.C. size: 76000 vx\n",
      "S.T.s.br. size: 44688 vx\n",
      "Sc.Cal.-S.Li. size: 48048 vx\n",
      "S.T.s. size: 63648 vx\n",
      "F.C.L.p.-subsc.-F.C.L.a.-INSULA. size: 83028 vx\n",
      "S.C.-S.Pe.C. size: 100674 vx\n",
      "OCCIPITAL size: 48300 vx\n"
     ]
    }
   ],
   "source": [
    "# create yamls\n",
    "\n",
    "# start from an existing config\n",
    "starting_sulcus = 'S.Or.' # NEED TO WRITE THE SOr RIGHT AND LEFT CONFIG MANUALLY FIRST\n",
    "rotated = '_rotated'\n",
    "rotated = ''\n",
    "no_dot_starting_sulcus = ''.join(starting_sulcus.split('.'))\n",
    "config_path = f'/volatile/jl277509/Runs/02_STS_babies/Program/2023_jlaval_STSbabies/contrastive/configs/dataset/julien/sparse_load/{rotated}'\n",
    "\n",
    "sides = {'right': 'R', 'left': 'L'}\n",
    "for side, side_abrev in sides.items():\n",
    "    with open(os.path.join(config_path, f'{no_dot_starting_sulcus}_{side}_UKB_sparse_load.yaml'), 'r') as file:\n",
    "        starting_config = yaml.safe_load(file)\n",
    "\n",
    "    sulcus_list = ['F.Coll.-S.Rh.', 'S.F.inf.-BROCA-S.Pe.C.inf.', \\\n",
    "                'S.Po.C.', 'fronto-parietal_medial_face.', 'S.T.s.-S.GSM.', \\\n",
    "                'F.C.L.p.-S.GSM.', 'S.C.-S.Po.C.', 'S.F.inter.-S.F.sup.', 'F.C.M.post.-S.p.C.', \\\n",
    "                'S.s.P.-S.Pa.int.', 'S.Or.-S.Olf.', 'F.P.O.-S.Cu.-Sc.Cal.', 'S.F.marginal-S.F.inf.ant.', \\\n",
    "                'S.F.int.-F.C.M.ant.', 'S.T.i.-S.T.s.-S.T.pol.', 'S.F.int.-S.R.', 'Lobule_parietal_sup.', \\\n",
    "                'S.T.i.-S.O.T.lat.', 'S.Pe.C.', 'S.T.s.br.', 'Sc.Cal.-S.Li.', 'S.T.s.', 'F.C.L.p.-subsc.-F.C.L.a.-INSULA.', \\\n",
    "                'S.C.-S.Pe.C.', 'OCCIPITAL']\n",
    "\n",
    "    for target_sulcus in sulcus_list:\n",
    "        # dataset name\n",
    "        no_dot_target_sulcus = ''.join(target_sulcus.split('.'))\n",
    "        target_config = copy.deepcopy(starting_config)\n",
    "        target_config['dataset_name']=f'{no_dot_target_sulcus}_{side}_UKB_sparse_load'\n",
    "        # shape\n",
    "        filename = f'/neurospin/dico/data/deep_folding/current/datasets/UkBioBank/crops/2mm/{target_sulcus}/mask/{side_abrev}skeleton{rotated}.npy'\n",
    "        mmapped_array = np.load(filename, mmap_mode='r')\n",
    "        shape = tuple([1] + list(mmapped_array.shape[1:4]))\n",
    "        print(f'{target_sulcus} size: {np.prod(shape)} vx')\n",
    "        shape = str(shape)\n",
    "        target_config['input_size']=shape\n",
    "        # dirs\n",
    "        for key, value in starting_config.items():\n",
    "            if isinstance(value, str):\n",
    "                if starting_sulcus in value:\n",
    "                    new_value = value.replace(starting_sulcus, target_sulcus)\n",
    "                    target_config[key]=new_value\n",
    "\n",
    "        save_path = os.path.join(config_path, f'{no_dot_target_sulcus}_{side}_UKB_sparse_load.yaml')\n",
    "        with open(save_path, 'w') as outfile:\n",
    "            outfile.write(f'# @package dataset.{no_dot_target_sulcus}_{side}_UKB_sparse_load\\n')\n",
    "            yaml.dump(target_config,\n",
    "                    outfile,\n",
    "                    sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F.Coll.-S.Rh. size: 86428 vx\n",
      "S.F.inf.-BROCA-S.Pe.C.inf. size: 44720 vx\n",
      "S.Po.C. size: 57498 vx\n",
      "fronto-parietal_medial_face. size: 114144 vx\n",
      "F.I.P. size: 77220 vx\n",
      "S.T.s.-S.GSM. size: 63648 vx\n",
      "CINGULATE. size: 21904 vx\n",
      "F.C.L.p.-S.GSM. size: 52245 vx\n",
      "S.C.-S.Po.C. size: 88494 vx\n",
      "S.F.inter.-S.F.sup. size: 82150 vx\n",
      "F.C.M.post.-S.p.C. size: 24769 vx\n",
      "S.s.P.-S.Pa.int. size: 33626 vx\n",
      "S.Or.-S.Olf. size: 28272 vx\n",
      "F.P.O.-S.Cu.-Sc.Cal. size: 60060 vx\n",
      "S.F.marginal-S.F.inf.ant. size: 44928 vx\n",
      "S.F.int.-F.C.M.ant. size: 52326 vx\n",
      "S.T.i.-S.T.s.-S.T.pol. size: 116424 vx\n",
      "S.F.int.-S.R. size: 57171 vx\n",
      "Lobule_parietal_sup. size: 88560 vx\n",
      "S.T.i.-S.O.T.lat. size: 110448 vx\n",
      "S.Pe.C. size: 76000 vx\n",
      "S.T.s.br. size: 44688 vx\n",
      "Sc.Cal.-S.Li. size: 48048 vx\n",
      "S.T.s. size: 63648 vx\n",
      "F.C.L.p.-subsc.-F.C.L.a.-INSULA. size: 83028 vx\n",
      "S.C.-sylv. size: 69972 vx\n",
      "S.C.-S.Pe.C. size: 100674 vx\n",
      "OCCIPITAL size: 48300 vx\n",
      "S.Or. size: 20332 vx\n"
     ]
    }
   ],
   "source": [
    "# same with 5000 subjects\n",
    "\n",
    "# create yamls\n",
    "\n",
    "# start from an existing config\n",
    "# right side !\n",
    "starting_sulcus = 'S.F.median-S.F.pol.tr.-S.F.sup.'\n",
    "no_dot_starting_sulcus = ''.join(starting_sulcus.split('.'))\n",
    "config_path = '/volatile/jl277509/Runs/02_STS_babies/Program/2023_jlaval_STSbabies/contrastive/configs/dataset/julien/sparse_load/5000_subjects'\n",
    "with open(os.path.join(config_path, f'{no_dot_starting_sulcus}_right_UKB_sparse_load_5000.yaml'), 'r') as file:\n",
    "    starting_config = yaml.safe_load(file)\n",
    "\n",
    "sulcus_list = ['F.Coll.-S.Rh.', 'S.F.inf.-BROCA-S.Pe.C.inf.', \\\n",
    "               'S.Po.C.', 'fronto-parietal_medial_face.', 'F.I.P.', 'S.T.s.-S.GSM.', 'CINGULATE.', \\\n",
    "               'F.C.L.p.-S.GSM.', 'S.C.-S.Po.C.', 'S.F.inter.-S.F.sup.', 'F.C.M.post.-S.p.C.', \\\n",
    "               'S.s.P.-S.Pa.int.', 'S.Or.-S.Olf.', 'F.P.O.-S.Cu.-Sc.Cal.', 'S.F.marginal-S.F.inf.ant.', \\\n",
    "               'S.F.int.-F.C.M.ant.', 'S.T.i.-S.T.s.-S.T.pol.', 'S.F.int.-S.R.', 'Lobule_parietal_sup.', \\\n",
    "               'S.T.i.-S.O.T.lat.', 'S.Pe.C.', 'S.T.s.br.', 'Sc.Cal.-S.Li.', 'S.T.s.', 'F.C.L.p.-subsc.-F.C.L.a.-INSULA.', \\\n",
    "               'S.C.-sylv.', 'S.C.-S.Pe.C.', 'OCCIPITAL', 'S.Or.']\n",
    "\n",
    "for target_sulcus in sulcus_list:\n",
    "    # dataset name\n",
    "    no_dot_target_sulcus = ''.join(target_sulcus.split('.'))\n",
    "    target_config = copy.deepcopy(starting_config)\n",
    "    target_config['dataset_name']=f'{no_dot_target_sulcus}_right_UKB_sparse_load_5000'\n",
    "    # shape\n",
    "    filename = f'/neurospin/dico/data/deep_folding/current/datasets/UkBioBank/crops/2mm/{target_sulcus}/mask/Rskeleton.npy'\n",
    "    mmapped_array = np.load(filename, mmap_mode='r')\n",
    "    shape = tuple([1] + list(mmapped_array.shape[1:4]))\n",
    "    print(f'{target_sulcus} size: {np.prod(shape)} vx')\n",
    "    shape = str(shape)\n",
    "    target_config['input_size']=shape\n",
    "    # dirs\n",
    "    for key, value in starting_config.items():\n",
    "        if isinstance(value, str):\n",
    "            if starting_sulcus in value:\n",
    "                new_value = value.replace(starting_sulcus, target_sulcus)\n",
    "                target_config[key]=new_value\n",
    "\n",
    "    save_path = os.path.join(config_path, f'{no_dot_target_sulcus}_right_UKB_sparse_load_5000.yaml')\n",
    "    with open(save_path, 'w') as outfile:\n",
    "        yaml.dump(target_config,\n",
    "                  outfile,\n",
    "                  sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
